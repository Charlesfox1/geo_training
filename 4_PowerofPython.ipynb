{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not meant as an introductory lecture - this notebook showcases some of the more high-end techniques available to advanced and experienced python users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install rasterstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy_financial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install loguru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install cvxpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/Charlesfox1/geo_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard libs\n",
    "import time\n",
    "import numpy as np\n",
    "from loguru import logger\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "# financial libs\n",
    "import numpy_financial as npf\n",
    "\n",
    "# graphical libs\n",
    "import plotly.express as px\n",
    "import folium\n",
    "\n",
    "# geospatial libs\n",
    "from shapely.geometry import Point\n",
    "import pandas as pd\n",
    "pd.set_option('display.precision', 1)\n",
    "import geopandas as gpd\n",
    "#from geo_training import geo_utils\n",
    "import rasterio\n",
    "import rasterstats\n",
    "\n",
    "# webscraping\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MonteCarlo Simulation\n",
    "- use python to construct much more advanced scenario simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def revenue_growth_pct():\n",
    "    # Draw from a normal distribution, shifted, mean of 5, s.d. of 1\n",
    "    return np.random.normal(loc=5, scale=1.0)\n",
    "\n",
    "def gross_profit_margin_pct():\n",
    "    # centre around 25%\n",
    "    return np.random.normal(loc=45, scale=1)\n",
    "\n",
    "def sg_and_a_growth_pct():\n",
    "    # Draw from a normal distribution, shifted, mean of 5, s.d. of 1\n",
    "    return np.random.normal(loc=3, scale=1.0)\n",
    "\n",
    "def capex_required():\n",
    "    # Draw from a beta distribution, shifted, mean of 5, s.d. of 1\n",
    "    x = np.random.beta(a=5, b=5)\n",
    "    if x > 0.65:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def capex_spend():\n",
    "    # spend of at least 100... could be a lot more...\n",
    "    return min(np.random.pareto(a=1) * 5 + 100, 5000)\n",
    "\n",
    "def debt_cost_pct():\n",
    "    # normal distribution centred on 5%, .s.d 1%, minimum of 2%\n",
    "    return round(max(np.random.normal(loc=5, scale=1), 2), 1)\n",
    "\n",
    "\n",
    "def scenario(_input):\n",
    "    \n",
    "    V = _input[0]\n",
    "    years_to_model = _input[1]\n",
    "    \n",
    "    # Instantiate local variables\n",
    "    revenue = V['initial_revenue']\n",
    "    tax_rate_pct = V['tax_rate_pct']\n",
    "    debt = V['initial_debt']\n",
    "    sg_and_a = V['initial_sg_and_a']\n",
    "    depreciable_assets = V['initial_depreciable_assets']\n",
    "    depreciation_charge = depreciable_assets * (1 / V['depreciation_lifetime_years'])\n",
    "    \n",
    "    res = []\n",
    "    for year in range(0, years_to_model):\n",
    "        \n",
    "        # This year's revenue is last year's multiplied by some growth\n",
    "        revenue = revenue * ((100 + revenue_growth_pct()) / 100)\n",
    "        # Gross profit is some fraction of revenue\n",
    "        gross_margin = gross_profit_margin_pct() / 100\n",
    "        gross_profit = revenue * gross_margin\n",
    "        # COGS is the delta\n",
    "        cogs = revenue - gross_profit\n",
    "        # Grow SG&A\n",
    "        sg_and_a = sg_and_a * ((100 + sg_and_a_growth_pct()) / 100)\n",
    "        # EBITDA\n",
    "        ebitda = gross_profit - sg_and_a\n",
    "        # Depreciate assets - straightline (fixed annual charge)\n",
    "        depreciable_assets -= depreciation_charge\n",
    "        # EBIT\n",
    "        ebit = ebitda - depreciation_charge\n",
    "        # Interest\n",
    "        if year < V['years_until_refinance']:\n",
    "            interest_rate_pct = V['initial_interest_pct']\n",
    "        elif year == V['years_until_refinance']:\n",
    "            interest_rate_pct = debt_cost_pct()\n",
    "        interest_charge = debt * ((interest_rate_pct) / 100)\n",
    "        # Tax\n",
    "        ebt = ebit - interest_charge\n",
    "        tax = max(ebt * (tax_rate_pct / 100), 0)\n",
    "        # PAT\n",
    "        pat = ebt - tax\n",
    "        # CAPEX\n",
    "        if capex_required():\n",
    "            capex = capex_spend()\n",
    "        else:\n",
    "            capex = 0\n",
    "        # FCFE - Assume no change in Working Capital, Net Borrowing for simplicity\n",
    "        fcfe = ebitda - interest_charge - tax - capex\n",
    "        \n",
    "        # add financials to a list, store\n",
    "        res.append(\n",
    "            (year, revenue,cogs,gross_profit,sg_and_a,\n",
    "             ebitda,depreciation_charge,ebit,interest_rate_pct,\n",
    "             interest_charge,ebt,tax,pat,capex,fcfe\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    # generate financials dataframe for this scenario\n",
    "    df = pd.DataFrame(res, columns = \n",
    "                     ['year','revenue','cogs',\n",
    "                      'gross_profit','sg_and_a','ebitda',\n",
    "                      'depreciation_charge','ebit','interest_rate',\n",
    "                      'interest_charge','ebt','tax','pat','capex','fcfe'])\n",
    "    \n",
    "    # Define cashflow stream for valuation\n",
    "    cashflows = [-V['business_purchase_cost']] + list(df['fcfe'])\n",
    "    \n",
    "    # Summary dictionary\n",
    "    summary = {'revenue_cagr': round(((revenue / V['initial_revenue']) ** (1/years_to_model)) - 1,4),\n",
    "            'avg_gross_margin': round(np.mean(df['gross_profit'] / df['revenue']),4),\n",
    "            'refinance_interest_rate':round(interest_rate_pct / 100,4),\n",
    "            'total_capex_as_pct_of_revenue':round(df['capex'].sum() / df['revenue'].sum(),4),\n",
    "            'sg_and_a_as_pct_of_revenue': round(df['sg_and_a'].sum() / df['revenue'].sum(),4),\n",
    "            'IRR': round(npf.irr(cashflows),3),\n",
    "            'NPV': round(npf.npv(V['discount_factor'], cashflows),1)\n",
    "           }\n",
    "    \n",
    "    return summary, df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Common Start Variables\n",
    "V = {\n",
    "    'initial_revenue':650,\n",
    "    'tax_rate_pct':20,\n",
    "    'initial_debt':4000,\n",
    "    'initial_interest_pct':2,\n",
    "    'years_until_refinance':5,\n",
    "    'initial_sg_and_a':45,\n",
    "    'initial_depreciable_assets':550,\n",
    "    'depreciation_lifetime_years':10,\n",
    "    'business_purchase_cost':1000,\n",
    "    'discount_factor':0.07\n",
    "}\n",
    "\n",
    "_input = (V, 10)\n",
    "\n",
    "scenario(_input)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario(_input)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "_ = scenario(_input)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_input = (V, 10)\n",
    "scenarios = []\n",
    "financial_dfs = {}\n",
    "# run 10,000 scenarios\n",
    "start_time = time.time()\n",
    "for i in range(10000):\n",
    "    output = scenario(_input)\n",
    "    results = output[0]\n",
    "    results['scenario_id'] = i\n",
    "    scenarios.append(results)\n",
    "    financial_dfs[i] = output[1]\n",
    "end_time = time.time()\n",
    "print(f'Time elapsed: {round(end_time - start_time, 2)}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the results\n",
    "mdf = pd.DataFrame(scenarios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Options\n",
    "- Visualise scenarios by condition (e.g. count of scenarios by IRR)\n",
    "- Investigate this dataset with regression / PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example / Starter: Visualise scenarios by IRR, colour by different variables\n",
    "x = 'IRR'\n",
    "y = 'avg_gross_margin'\n",
    "\n",
    "fig = px.scatter(mdf, # output dataframe\n",
    "                 x=x, \n",
    "                 y=y,\n",
    "                 hover_data=['scenario_id'])\n",
    "\n",
    "fig.update_xaxes(range=[-0.1,0.2], \n",
    "                 title = x,\n",
    "                 tickformat = '.0%',  \n",
    "                 gridcolor='lightgrey', # grid lines\n",
    "                 linecolor='darkgrey', # axis line\n",
    "                )\n",
    "\n",
    "fig.update_yaxes(title = 'Average Gross Margin', \n",
    "                 tickformat = '.0%', \n",
    "                 dtick = 0.01,  \n",
    "                 gridcolor='lightgrey', \n",
    "                 linecolor='darkgrey'\n",
    "                )\n",
    "\n",
    "fig.update_traces(marker=dict(size=3, \n",
    "                              color = 'rgb(0, 42, 94)'))\n",
    "\n",
    "fig.update_layout(height = 600, \n",
    "                  width = 800, \n",
    "                  plot_bgcolor='white'\n",
    "                 )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion - not a huge relationship between IRR and gross margin - something else might be more important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example / Starter: Visualise scenarios by IRR, colour by different variables\n",
    "x = 'IRR'\n",
    "y = 'refinance_interest_rate'\n",
    "\n",
    "fig = px.scatter(mdf, # output dataframe\n",
    "                 x=x, \n",
    "                 y=y,\n",
    "                 hover_data=['scenario_id'])\n",
    "\n",
    "fig.update_xaxes(range=[-0.1,0.2], \n",
    "                 title = x,\n",
    "                 tickformat = '.0%',  \n",
    "                 gridcolor='lightgrey', # grid lines\n",
    "                 linecolor='darkgrey', # axis line\n",
    "                )\n",
    "\n",
    "fig.update_yaxes(title = 'Refinance Interest Rate', \n",
    "                 tickformat = '.0%', \n",
    "                 dtick = 0.01,  \n",
    "                 gridcolor='lightgrey', \n",
    "                 linecolor='darkgrey'\n",
    "                )\n",
    "\n",
    "fig.update_traces(marker=dict(size=3, \n",
    "                              color = 'rgb(0, 42, 94)'))\n",
    "\n",
    "fig.update_layout(height = 600, \n",
    "                  width = 800, \n",
    "                  plot_bgcolor='white'\n",
    "                 )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion - strong negative relationship between IRR and Refinance interest rate\n",
    "- more important to watch refinancing for this company than margin progression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'IRR'\n",
    "y = 'total_capex_as_pct_of_revenue'\n",
    "\n",
    "fig = px.scatter(mdf, # output dataframe\n",
    "                 x=x, \n",
    "                 y=y,\n",
    "                 hover_data=['scenario_id'])\n",
    "\n",
    "fig.update_xaxes(range=[-0.1,0.2], \n",
    "                 title = x,\n",
    "                 tickformat = '.0%',  \n",
    "                 gridcolor='lightgrey', # grid lines\n",
    "                 linecolor='darkgrey', # axis line\n",
    "                )\n",
    "\n",
    "fig.update_yaxes(range=[0,0.12],\n",
    "                 title = 'Total Capex as % of Revenue', \n",
    "                 tickformat = '.0%', \n",
    "                 dtick = 0.01,  \n",
    "                 gridcolor='lightgrey', \n",
    "                 linecolor='darkgrey'\n",
    "                )\n",
    "\n",
    "fig.add_vline(x=0)\n",
    "\n",
    "fig.update_traces(marker=dict(size=3, \n",
    "                              color = 'rgb(0, 42, 94)'))\n",
    "\n",
    "fig.update_layout(height = 600, \n",
    "                  width = 800, \n",
    "                  plot_bgcolor='white'\n",
    "                 )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example / Starter: Visualise scenarios by IRR, colour by different variables\n",
    "x = 'IRR'\n",
    "y = 'total_capex_as_pct_of_revenue'\n",
    "fig = px.scatter(mdf, \n",
    "                 x=x, \n",
    "                 y=y,\n",
    "                 color='refinance_interest_rate',\n",
    "                 hover_data=['scenario_id'])\n",
    "\n",
    "fig.update_xaxes(range=[-0.1,0.2], \n",
    "                 title = x,\n",
    "                 tickformat = '.0%',  \n",
    "                 gridcolor='lightgrey', # grid lines\n",
    "                 linecolor='darkgrey', # axis line\n",
    "                )\n",
    "\n",
    "fig.update_yaxes(range=[0,0.12],\n",
    "                 title = 'Total Capex as % of Revenue', \n",
    "                 tickformat = '.0%', \n",
    "                 dtick = 0.01,  \n",
    "                 gridcolor='lightgrey', \n",
    "                 linecolor='darkgrey'\n",
    "                )\n",
    "\n",
    "fig.add_vline(x=0)\n",
    "\n",
    "fig.update_traces(marker=dict(size=3))\n",
    "\n",
    "fig.update_layout(height = 600, \n",
    "                  width = 800, \n",
    "                  plot_bgcolor='white'\n",
    "                 )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multithreading: Use the Whole Computer\n",
    "- Distribute independent tasks across available threads - e.g, montecarlo simulations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out what compute we have available\n",
    "cpus = cpu_count()\n",
    "logger.info(f\"Detected {cpus} cores on the machine\")\n",
    "\n",
    "def f(x):\n",
    "    # Simple work function\n",
    "    return x*x\n",
    "\n",
    "# Bundle of inputs\n",
    "number_of_scenarios = range(1000)\n",
    "\n",
    "# Ensure entry at master process level\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # Create a CPU pool\n",
    "    with Pool(cpus) as p:\n",
    "        \n",
    "        results = p.map(f, number_of_scenarios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now let's run our Montecarlo simulation, but multi-threaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find out what compute we have available\n",
    "cpus = cpu_count()\n",
    "logger.info(f\"Detected {cpus} cores on the machine\")\n",
    "\n",
    "# Bundle of inputs\n",
    "number_of_scenarios = 10000\n",
    "\n",
    "# Ensure entry at master process level\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create a CPU pool\n",
    "    with Pool(cpus) as p:\n",
    "        \n",
    "        # map the work to the pool, gather the results\n",
    "        scenarios_pooled = p.map(scenario, [(V, 10)]*number_of_scenarios)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f'Time elapsed: {round(end_time - start_time, 2)}s when distributed across {cpus} CPUs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geospatial Data\n",
    "- Use geospatial data to sense-check company expansion plans, optimise real estate positioning, etc. \n",
    "- Schroders has expanded and has decided to launch a range of cheap Scandinanvian furniture (\"SchroKEA\"). they have identified 10 potential locations in London for their first store. Which location gives them the greatest addressable market in 20 minutes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import locations\n",
    "locations = gpd.read_file('geo_training/locations.geojson')\n",
    "locations = locations.set_index('id')\n",
    "\n",
    "# Use TravelTime API service to generate 20-minute isochrone\n",
    "\n",
    "creds = {'X-Application-Id':os.getenv('X_APPLICATION_ID'),\n",
    "         'X-Api-Key':os.getenv('X_API_KEY')}\n",
    "        \n",
    "travel_time_mins = 20\n",
    "isos = []\n",
    "for _id_, location in locations.iterrows():\n",
    "    \n",
    "    iso = geo_utils.tt_isochrone(location.geometry, \n",
    "                                 travel_time_mins = 20,\n",
    "                                 creds = creds, # I can't share these!\n",
    "                                 mode = 'public_transport',\n",
    "                                 _id_ = str(_id_)\n",
    "                                )\n",
    "    \n",
    "    isos.append(iso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_gdf = gpd.GeoDataFrame(pd.concat(isos), crs = 4326, geometry = 'geometry')\n",
    "iso_gdf.index = iso_gdf.index.astype(int)\n",
    "iso_gdf = iso_gdf.join(locations[['location']]).reset_index()\n",
    "iso_gdf.to_file('geo_training/isochrones.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_gdf = gpd.read_file('geo_training/isochrones.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# let's visualise our isochrones for each location, in a different colour each time\n",
    "colour_map = {1:\"rgb(0,42,94)\",\n",
    "             2:\"rgb(0,121,109)\",\n",
    "             3:\"rgb(234,82,4)\",\n",
    "             4:\"rgb(183,25,98)\",\n",
    "             5:\"rgb(79,51,152)\",\n",
    "             6:\"rgb(0,116,183)\",\n",
    "             7:\"rgb(99,197,50)\",\n",
    "             8:\"rgb(248,169,8)\",\n",
    "             9:\"rgb(223,83,106)\",\n",
    "             10:\"rgb(125,55,135)\"}\n",
    "\n",
    "import folium\n",
    "m = folium.Map(location=[51.5074, -0.1278], \n",
    "               zoom_start=12,\n",
    "               width=1000,\n",
    "               height=800)  \n",
    "\n",
    "# Define the style function  \n",
    "def style_function(feature):  \n",
    "    \n",
    "    # Get the value for coloring from the feature properties  \n",
    "    value = feature['properties']['search_id']\n",
    "      \n",
    "    # Get the color based on the value using the color map  \n",
    "    colour = colour_map.get(value) \n",
    "      \n",
    "    # Return the style properties  \n",
    "    return {  \n",
    "        'fillColor': colour,  \n",
    "        'color': 'black',  \n",
    "        'weight': 1,  \n",
    "        'fillOpacity': 0.6,\n",
    "    }  \n",
    "\n",
    "folium.GeoJson(iso_gdf, \n",
    "               style_function=style_function,\n",
    "               tooltip=folium.GeoJsonTooltip(fields=['location'])\n",
    "            ).add_to(m)\n",
    "\n",
    "display(m)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now, let's import a population dataset so we can see which isochrone affords us the biggest market\n",
    "with rasterio.open('clipped_GBR_worldpop.tif') as r:\n",
    "    arr = r.read(1)\n",
    "    arr[arr<0] = 0\n",
    "    aff = r.meta['transform']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# click \"raster.PNG\" from the files list on the left hand side..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what does the population data look like \"under the hood\"?\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample raster for each polygon in iso_gdf\n",
    "zs = rasterstats.zonal_stats(iso_gdf, arr, affine=aff, stats=['sum'])\n",
    "iso_gdf['20_min_pop'] = [i['sum'] for i in zs]\n",
    "iso_gdf = iso_gdf.sort_values(by = '20_min_pop', ascending = False)\n",
    "iso_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SchrodKEA should set up shop in E&C and Kilburn first, rather than somewhere more central like Westminster - due to a combination of the immediate resident population density + public transport availability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative Data - Web Scraping\n",
    "- Gather non-standard data from the internet to augment traditional decision making\n",
    "- e.g. gather all the property information on this webpage: https://www.rexfordindustrial.com/properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.rexfordindustrial.com/properties'\n",
    "r = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(r.content, 'html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_prop_divs = soup.find('div', attrs = {'class':'properties-listing'}).find_all('article')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_collection = []\n",
    "for a in all_prop_divs:\n",
    "    p = {'prop_name':a.find('h1').text,\n",
    "         'location':a.find('h2').text,\n",
    "         'available_space':a.find_all('h3')[0].text,\n",
    "         'total_space':a.find_all('h3')[1].text\n",
    "         }\n",
    "    prop_collection.append(p)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this alternative data to track concepts of interest to us...e.g.:\n",
    "- \"What is the fraction of total space, across all warehouse properties, that is currently vacanct?\n",
    "- \"Which property has the highest vacancy rate?\n",
    "- \"Any patterns / identifying factors for the most vacant properties\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pd.DataFrame(prop_collection)\n",
    "\n",
    "pdf['available_space'].str.split(' ').str[0].str.replace(', ','')\n",
    "\n",
    "pdf['available_space'] = pd.to_numeric(pdf['available_space'].str.split(' ').str[0].str.replace(',',''), \n",
    "                                       errors = 'coerce').fillna(0)\n",
    "\n",
    "pdf['total_space'] = pd.to_numeric(pdf['total_space'].str.split(' ').str[0].str.replace(',',''), \n",
    "                                       errors = 'coerce').fillna(0)\n",
    "\n",
    "overall_vacancy_rate = pdf['available_space'].sum() / pdf['total_space'].sum()\n",
    "\n",
    "str(round(overall_vacancy_rate * 100, 2))+' percent'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pdf['vacancy_rate'] = (pdf['available_space'] / pdf['total_space']) * 100\n",
    "pdf.sort_values(by = 'vacancy_rate', ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf[pdf['vacancy_rate'] > 80].total_space.mean().round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf[pdf['vacancy_rate'] < 80].total_space.mean().round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.total_space.mean().round(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...The vacant properties are significantly smaller than average for Rexford... are smaller properties harder to lease, or do they have a higher turnover rate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus: Machine Learning\n",
    "- Harness cutting-edge techniques to make predictions for variables of interest\n",
    "- Better to use Kaggle than look at something I put together! https://www.kaggle.com/code/janiobachmann/credit-fraud-dealing-with-imbalanced-datasets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markowitz Portfolio Optimisation\n",
    "- Solve optimisation problems, traditional risk-return portfolio optimisation\n",
    "- turbo charge this with parametric bootstrapping (generate many future scenarios, solve for each!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "from sklearn.datasets import make_spd_matrix\n",
    "import matplotlib as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Expected Returns\n",
    "(Entry point for substituting in actual datapoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "er_names = ['Emerging Markets Equity', \n",
    "            'EAFE Equity', 'U.S. Small Cap',\n",
    "            'U.S. Mid Cap', \n",
    "            'U.S. Large Cap', \n",
    "            'U.S. High Yield Bonds',\n",
    "            'Commodities', \n",
    "            'U.S. Inv. Grade Corporate Bonds',\n",
    "            'U.S. Intermediate Treasuries', \n",
    "            'TIPS',\n",
    "            'World ex-U.S. Government Bonds']\n",
    "\n",
    "random_seed = 2355\n",
    "np.random.seed(random_seed) # set random state for reproducibility\n",
    "er_values = np.random.rand(len(er_names)) / 10\n",
    "er = pd.Series(er_values, index=er_names)\n",
    "er"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Covariance Matrix\n",
    "The function 'make_spd_matrix' generates a random covariance matrix \n",
    "<i>See: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_spd_matrix.html </i>\n",
    "(Entry point for replacing with a pre-calculated, real covariance matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_dim = er.shape[0]\n",
    "cov_m = make_spd_matrix(cov_dim, \n",
    "                        random_state=random_seed)\n",
    "\n",
    "# get the diagonal of the matrix and get an array of the indicies in order\n",
    "order = (-np.diagonal(cov_m)).argsort()\n",
    "\n",
    "# use that to build a permutation matrix\n",
    "\n",
    "p = np.eye(cov_dim)[order, :]\n",
    "# permute the covariance matrix so it's in order\n",
    "o_cov = p @ cov_m @ p.T\n",
    "\n",
    "cov = pd.DataFrame(o_cov)\n",
    "cov.index = er.index\n",
    "cov.columns = er.index\n",
    "cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also visualise this very cheaply\n",
    "px.imshow(o_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimisation_simple(Return, risk, gamma, w, optim_params):\n",
    "    \n",
    "    \"\"\"\n",
    "    simple optimisation - directly inject gamma values into the problem from a risk-aversion logspace\n",
    "    \"\"\"\n",
    "    \n",
    "    # define problem, params - standard Markowitz portfolio optimisation \n",
    "    prob = cp.Problem(cp.Maximize(Return - gamma * risk), # maximise return for a given level of risk\n",
    "                      [cp.sum(w) == 1, # constaint: ensure our portfolio weights sum to 1\n",
    "                       w >= 0.0 # constaint:ensure every weight is greater or equal to 0 - no shorting\n",
    "                      ] \n",
    "                     )\n",
    "    \n",
    "    risk_data = np.zeros(optim_params['samples']) # setup container\n",
    "    Return_data = np.zeros(optim_params['samples']) # setup container\n",
    "    weights = [] # setup container\n",
    "    \n",
    "    # define our levels of risk aversion\n",
    "    gamma_vals = np.logspace(-2, 1, num=optim_params['samples'])\n",
    "    \n",
    "    for i in range(optim_params['samples']):\n",
    "        gamma.value = gamma_vals[i]\n",
    "        prob.solve()\n",
    "        risk_data[i] = cp.sqrt(risk).value\n",
    "        Return_data[i] = Return.value\n",
    "        weights.append(np.squeeze(np.asarray(w.value)))\n",
    "        \n",
    "    return risk_data, Return_data, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulations(er: pd.Series, \n",
    "                    cov: pd.DataFrame, \n",
    "                    number_of_sims: int, \n",
    "                    optim_params: dict):\n",
    "    \n",
    "    # Create a monthly datetime index\n",
    "    dates = pd.date_range(start='2010-08-31', \n",
    "                          periods=120, \n",
    "                          freq='M')\n",
    "\n",
    "    # Generate 10 years of monthly data by sampling (\"parametric bootstraping\")\n",
    "    # these will be carried forward for all of the simulations\n",
    "    data = []\n",
    "    for i in range(0, number_of_sims):\n",
    "        if i+1 % 5 == 0:\n",
    "            print(f\"Generating data for sim {i+1}\")\n",
    "        data.append(\n",
    "            pd.DataFrame(\n",
    "                columns = cov.columns,\n",
    "                index = dates,\n",
    "                data = np.random.multivariate_normal(er.values, cov.values, 120)\n",
    "            ))\n",
    "        \n",
    "    # Store values from Optimisation \n",
    "    stdev_col = [None for i in range(number_of_sims)]\n",
    "    exp_ret_col = [None for i in range(number_of_sims)]\n",
    "    weight_col = [None for i in range(number_of_sims)]\n",
    "    \n",
    "    # For each forward return simulation, find the optimal portfolio\n",
    "    for i in range(number_of_sims):\n",
    "        if i+1 % 5 == 0:\n",
    "            print(f\"Building portfolios for sim {i+1}\")\n",
    "            \n",
    "        this_simulation_returns = data[i]\n",
    "        \n",
    "        # Set Problem Parameters in this scenario\n",
    "        n = len(this_simulation_returns.columns) # number of securities\n",
    "        w = cp.Variable(n) # setup a variable, w, of array size n\n",
    "        mu = this_simulation_returns.mean() * 12 # simple annualisation of returns\n",
    "        Sigma = this_simulation_returns.cov() * 12 # simple covariance of returns\n",
    "        gamma = cp.Parameter(nonneg=True) # risk aversion parameter\n",
    "        ret = mu.values.T @ w # return is a function of mean returns x portfolio weights\n",
    "        risk = cp.quad_form(w, Sigma.values) # risk is a quadratic form variable\n",
    "        \n",
    "        # Optimize over every simulation\n",
    "        stdev, exp_ret, weights = optimisation_simple( Return = ret, \n",
    "                                                            risk = risk, \n",
    "                                                            gamma = gamma, \n",
    "                                                            w = w, \n",
    "                                                            optim_params = optim_params)\n",
    "               \n",
    "        stdev_col[i] = stdev\n",
    "        exp_ret_col[i] = exp_ret\n",
    "        weight_col[i] = pd.DataFrame(data = weights, \n",
    "                                     columns = this_simulation_returns.columns)\n",
    "            \n",
    "    return weight_col, stdev_col, exp_ret_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIM_PARAMS = {'samples':200,\n",
    "                'sparse_samples':int(200 / 5),\n",
    "                'jumpsize':0.05}\n",
    "\n",
    "weight_col, stdev_col, exp_ret_col = run_simulations(er = er, \n",
    "                                                     cov = cov, \n",
    "                                                     number_of_sims = 10, \n",
    "                                                     optim_params = OPTIM_PARAMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise / Plot Efficient Frontiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "for i, result in enumerate(zip(stdev_col, exp_ret_col)):\n",
    "    risk = result[0]\n",
    "    rtn = result[1]\n",
    "    fig.add_trace(go.Scatter(x=risk, \n",
    "                             y=rtn, \n",
    "                             name=f'Simulation {i+1}'), \n",
    "                 )\n",
    "    \n",
    "xmin, xmax = (np.floor(min([min(sub.x) for sub in fig.data])), \n",
    "              np.ceil(max([max(sub.x) for sub in fig.data])) )\n",
    "ymin, ymax = (np.floor(min([min(sub.y) for sub in fig.data])), \n",
    "              np.ceil(max([max(sub.y) for sub in fig.data])) )\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis = {\n",
    "        \"range\": [xmin, xmax],\n",
    "        \"title\": 'Risk'\n",
    "    },\n",
    "    yaxis = {\n",
    "        \"range\": [ymin, ymax],\n",
    "        \"title\":'Return',\n",
    "    },\n",
    "    title = \"Markowitz Portfolio Optimisation - An Efficient Frontier for Every Future!\",\n",
    "    height=500,\n",
    "    template=\"plotly_white\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Concrete 3.9)",
   "language": "python",
   "name": "concrete_39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
